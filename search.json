[{"path":"https://merck.github.io/wpgsd/articles/wpgsd.html","id":"background","dir":"Articles","previous_headings":"","what":"Background","title":"Quickstart guide","text":"weighted parametric group sequential design (WPGSD) (Anderson et al. (2022)) approach allows one take advantage known correlation structure constructing efficacy bounds control family-wise error rate (FWER) group sequential design. correlation may due common observations nested populations, due common observations overlapping populations, due common observations control arm. document illustrates use WPGSD R package implement approach.","code":""},{"path":[]},{"path":"https://merck.github.io/wpgsd/articles/wpgsd.html","id":"closed-testing-and-parametric-tests","dir":"Articles","previous_headings":"Methods and Examples","what":"Closed Testing and Parametric Tests","title":"Quickstart guide","text":"aim control familywise error rate (FWER) level \\(\\alpha\\). Let \\(J \\subseteq \\). intersection hypothesis \\(H_J\\) assumes null hypothesis individual hypotheses \\(H_i\\) \\(\\J\\). Closed testing principle follows: sets \\(J \\subseteq \\) \\(j \\J\\), \\(H_J\\) can rejected level \\(\\alpha\\), \\(H_j\\) can rejected. Weighted parametric tests can used : Bretz et al. (2011), Xi et al. (2017) fixed designs Maurer Bretz (2013) group sequential.","code":""},{"path":"https://merck.github.io/wpgsd/articles/wpgsd.html","id":"consonance","dir":"Articles","previous_headings":"Methods and Examples","what":"Consonance","title":"Quickstart guide","text":"closed procedure called consonant rejection complete intersection null hypothesis \\(H_I\\) implies least one elementary hypothesis \\(H_i, \\\\), rejected. Consonance desirable property leading short-cut procedures give rejection decisions original closed procedure fewer operations. WPGSD, consonance always hold general closed-testing procedure required.","code":""},{"path":"https://merck.github.io/wpgsd/articles/wpgsd.html","id":"group-sequential-design-notations-and-assumptions","dir":"Articles","previous_headings":"Methods and Examples","what":"Group Sequential Design Notations and Assumptions","title":"Quickstart guide","text":"set \\(\\) hypotheses \\(\\\\). \\(K\\) group sequential analyses, \\(k=1,⋯,K\\) required, can generalized Assume tests \\(Z_{ik}\\), \\(\\\\), \\(1 \\leq k \\leq K\\) large \\(Z_{ik}\\) used reject \\(H_i\\)","code":""},{"path":"https://merck.github.io/wpgsd/articles/wpgsd.html","id":"correlation-structure","dir":"Articles","previous_headings":"Methods and Examples","what":"Correlation Structure","title":"Quickstart guide","text":"Events individual hypothesis \\(H_i\\),\\(\\\\) analysis k denoted \\(n_{ik}\\). Assume endpoint hypotheses (can relaxed) binary continuous outcomes \\(n_{ik}\\) represents sample size \\(Z_{ik}\\) standardized normal test treatment effect individual hypothesis \\(H_i\\) analysis \\(k\\) Denote \\(n_{\\wedge ^\\prime,k\\wedge k^\\prime}\\) number observations (events) included \\(Z_{ik}\\) \\(Z_{^\\prime k^\\prime}\\), \\(\\\\), \\(1\\le k\\le K\\). Key result \\[  \\hbox{Corr}(Z_{ik}, Z_{^\\prime k^\\prime }) =  \\frac{n_{\\wedge ^\\prime ,k\\wedge k^\\prime }}{\\sqrt{n_{ik}n_{^\\prime k^\\prime }}} \\] Proof builds standard group sequential theory (Chen et al. (2021))","code":""},{"path":"https://merck.github.io/wpgsd/articles/wpgsd.html","id":"example-1-overlapping-populations-two-analyses","dir":"Articles","previous_headings":"Methods and Examples","what":"Example 1: Overlapping Populations, Two Analyses","title":"Quickstart guide","text":"Following illustrates first example, overlapping populations (e.g. due biomarker) also example 1 Anderson et al. (2022). Ex1: Populations multiplicity strategy defined follows.  event count hypothesis analysis shown . Ex1: Event count correlation matrix among test statistics follows. Ex1: Correlation","code":"# transition matrix m <- matrix(c(   0, 0, 1,   0, 0, 1,   0.5, 0.5, 0 ), nrow = 3, byrow = TRUE) # weight matrix w <- c(0.3, 0.3, 0.4)  # multiplicity graph cbPalette <- c(\"#999999\", \"#E69F00\", \"#56B4E9\")  nameHypotheses <- c(   \"H1: Population 1\",   \"H2: Population 2\",   \"H3: Overall Population\" )  hplot <- hGraph(3,   alphaHypotheses = w,   m = m,   nameHypotheses = nameHypotheses,   trhw = .2, trhh = .1,   digits = 5, trdigits = 3, size = 5, halfWid = 1,   halfHgt = 0.5, offset = 0.2, trprop = 0.4,   fill = as.factor(c(2, 3, 1)),   palette = cbPalette,   wchar = \"w\" ) hplot"},{"path":"https://merck.github.io/wpgsd/articles/wpgsd.html","id":"example-2-common-control-two-analyses","dir":"Articles","previous_headings":"Methods and Examples","what":"Example 2: Common Control, Two Analyses","title":"Quickstart guide","text":"Following illustrates second example correlation comes common control arm. also example 2 Anderson et al. (2022).  Ex2: Event count Ex2: Correlation","code":""},{"path":"https://merck.github.io/wpgsd/articles/wpgsd.html","id":"hypotheses-set","dir":"Articles","previous_headings":"Methods and Examples","what":"Hypotheses Set","title":"Quickstart guide","text":"2 examples 7 intersection hypotheses corresponding weighting strategies illustrated . Ex1: Weighting Strategy Ex2: Weighting Strategy","code":""},{"path":"https://merck.github.io/wpgsd/articles/wpgsd.html","id":"alpha-spending-3-approaches","dir":"Articles","previous_headings":"Methods and Examples","what":"\\(\\alpha\\) Spending: 3 approaches","title":"Quickstart guide","text":"WPGSD approach uses known correlations tests study. relaxes bounds allows increased power smaller sample size. Three spending approaches proposed: Fixed spending (Fleming-Harrington-O’Brien (FHO) approach). Specify \\(0 < \\alpha_1(J) < \\alpha_2(J) < \\ldots < \\alpha_K(J) = \\alpha(J) \\leq \\alpha\\) \\(J\\subseteq \\), \\(\\alpha(J)\\) total alpha intersection hypothesis \\(H_J\\) according graphical approach. \\(\\alpha\\)-spending approach 1. choose spending function family \\(f(t,\\alpha)\\) set \\(\\alpha_k(J)=f(t_k(J),\\alpha(J))\\) \\(1\\le k\\le K\\) intersection hypotheses \\(J\\subseteq \\). \\(\\alpha\\)-spending approach 2. elementary hypothesis \\(\\) (\\(\\) = 1, 2, , \\(m\\)), specify \\(\\alpha\\)-spending function family \\(f_i(t,\\gamma)\\) \\(\\gamma\\) \\(\\alpha\\) level hypothesis \\(f_i(t_{ik},\\gamma)\\) determines much \\(\\alpha\\) spend analysis \\(k\\) hypothesis \\(\\) level \\(\\gamma\\) allocated hypothesis. \\(\\alpha_k(J) = \\sum_{\\J} f_i(t_{ik}, w_i(J)\\alpha)\\).","code":""},{"path":"https://merck.github.io/wpgsd/articles/wpgsd.html","id":"bounds-computation-parametric-test-fixed-design-eg--two-populations-one-analysis","dir":"Articles","previous_headings":"Methods and Examples","what":"Bounds Computation: Parametric Test, Fixed Design (eg. Two Populations, One Analysis)","title":"Quickstart guide","text":"Assume (\\(Z_1,Z_2\\)) bivariate normal known correlation Find \\(\\alpha\\)-inflation factor \\(c_J\\) \\[ \\alpha = P[\\cup_{\\J} \\{p_i \\leq c_Jw_{J,}\\alpha \\}] = P[\\cup_{\\J} \\{Z_i \\geq \\Phi^{-1}(1−c_Jw_{J,}\\alpha \\}]\\] Basic algorithm code Bretz et al. (2011)","code":""},{"path":"https://merck.github.io/wpgsd/articles/wpgsd.html","id":"bounds-computation-wpgsd---fixed-spending-and-alpha-spending-approach-1","dir":"Articles","previous_headings":"Methods and Examples > Bounds Computation: Parametric Test, Fixed Design (eg. Two Populations, One Analysis)","what":"Bounds Computation: WPGSD - Fixed spending and \\(\\alpha\\) spending approach 1","title":"Quickstart guide","text":"Assume \\(j < k\\) bounds \\(c_{ij} (J), \\J, j < k\\), already set remain unchanged. analysis \\(k\\), compute correlation matrix \\(Z_{ij}\\), \\(\\J\\), \\(j = 1, \\ldots, k\\). Initialize \\(\\alpha_{k}^{*}(J) = \\alpha_{k}(J) - \\alpha_{k-1}(J)\\). ii Set \\(b_{ik} = \\Phi^{-1}(1 - w_{}(J)\\alpha_{k}^{*} (J))\\), \\(\\J\\). iii Compute type error rate analysis \\(k\\) \\[ 1 - Pr(\\cap_{\\J} \\{ Z_{ik} < b_{ik} \\} \\cap_{\\J, j < k} \\{ Z_{ij} < c_{ij}(J) \\} ). \\] iv Update \\(\\alpha_{k}^{*}(J)\\) using root-finding steps ii - iii type error rate analysis \\(k\\) controlled \\(\\alpha_{k}(J)\\) \\(H_J\\). , \\[ 1 - Pr(\\cap_{\\J} \\{ Z_{ik} < b_{ik} \\} \\cap_{\\J, j < k} \\{ Z_{ij} < c_{ij}(J) \\} ) = \\alpha_{k}. \\] v Set \\(c_{ik}(J) = b_{ik}\\) previous step. corresponding nominal \\(p\\)-value boundary \\(p_{ik}(J)= 1-\\Phi(c_{ik}(J)) = w_i(J)\\alpha_k^*(J)\\). Note: interim bound depend future analyses. Solution requires root finding single \\(\\alpha_{k}^{*}(J)\\) time, \\(k=1,…,K\\). Requires multivariate normal computation mvtnorm R package Genz et al. (2020).","code":""},{"path":"https://merck.github.io/wpgsd/articles/wpgsd.html","id":"bounds-computation-wpgsd---alpha-spending-approach-2","dir":"Articles","previous_headings":"Methods and Examples > Bounds Computation: Parametric Test, Fixed Design (eg. Two Populations, One Analysis)","what":"Bounds Computation: WPGSD - \\(\\alpha\\) spending approach 2","title":"Quickstart guide","text":"Assume \\(j < k\\) bounds \\(c_{ij} (J), \\J, j < k\\), already set remain unchanged. analysis \\(k\\), compute correlation matrix \\(Z_{ij}\\), \\(\\J\\), \\(j = 1, \\ldots, k\\). Determine nominal \\(p\\)-value boundary elementary hypothesis \\(J\\) weighted Bonferroni test group sequential design described Maurer Bretz (2013). Let nominal \\(p\\)-value boundaries \\(\\alpha^\\prime_{ik}(J)\\). ii Choose inflation factor \\(\\xi_{k}(J) > 1\\) set \\[b_{ik} = \\Phi^{-1}(1 - \\xi_k(J) \\alpha^\\prime_{ik}(J)).\\] iii Update \\(\\xi_k(J)\\) type error rate analysis \\(k\\) controlled \\(\\alpha_{k}(J)\\) \\(H_J\\). , \\[ 1 - Pr(\\cap_{\\J} \\{ Z_{ik} < b_{ik} \\} \\cap_{\\J, j < k} \\{ Z_{ij} < c_{ij}(J) \\} ) = \\alpha_{k}(J).\\] iv appropriate \\(\\xi_k(J)\\) derived, nominal \\(p\\)-value boundaries \\(p_{ik}(J)=\\xi_k(J) \\alpha^\\prime_{ik}(J)\\), \\(b_{ik}\\) computed step ii, set \\(c_{ik}(J) = b_{ik}\\). Note: interim bound depend future analyses. Solution requires root finding single \\(\\xi_k(J)\\) time, k=1,…,K. Requires multivariate normal computation mvtnorm R package Genz et al. (2020).","code":""},{"path":"https://merck.github.io/wpgsd/articles/wpgsd.html","id":"implementation-of-example-1-with-overlapping-populations","dir":"Articles","previous_headings":"Methods and Examples","what":"Implementation of Example 1 with Overlapping Populations","title":"Quickstart guide","text":"first define transition matrix weights shown Section 2.5. Next set event count table follows: Analysis: Analysis number (1 interim, 2 final). Event: Event counts. (1, 1) represents counts hypothesis 1 (1, 2) counts intersection hypotheses 1 2 Event Count Event Count - Compute SAS Datasets Example compute correlation matrix using event count table generate_corr(). see correlations accounted Bonferroni approach substantial , thus, might expect non-trivial impact bounds hypothesis tests. Correlation Matrix Bonferroni WPGSD bounds can computed via generate_bounds(). example, useHSD(-4) \\(\\alpha\\)-spending hypotheses. note, generate_bounds() input type specifies boundary type. 0 = Bonferroni. Separate alpha spending hypotheses. 1 = Fixed alpha spending hypotheses. Method 3a manuscript. 2 = Overall alpha spending hypotheses. Method 3b manuscript. 3 = Separate alpha spending hypotheses. Method 3c manuscript. Compute Bonferroni bounds. Bonferroni bounds Compute WPGSD Bounds using \\(\\alpha\\)-spending approach 1 HSD(-4) spending. spending time defined minimum 3 observed information fractions. WPGSD bounds shows comparison Bonferroni WPGSD bounds. Nominal level final analysis using WPGSD method increased 1.3× obtained via Bonferroni approach. Bonferroni WPGSD Bounds Closed testing procedure can performed using closed_test(). Observed Nominal p-Values Closed Testing Results","code":"event <- tribble(   ~H1, ~H2, ~Analysis, ~Event,   1, 1, 1, 100,   2, 2, 1, 110,   3, 3, 1, 225,   1, 2, 1, 80,   1, 3, 1, 100,   2, 3, 1, 110,   1, 1, 2, 200,   2, 2, 2, 220,   3, 3, 2, 450,   1, 2, 2, 160,   1, 3, 2, 200,   2, 3, 2, 220 ) event %>%   kbl(caption = \"Event Count\", align = \"l\") %>%   kable_classic_2(full_width = FALSE) # Alternatively one can manually enter paths for analysis datasets, below example uses dummy data assuming currently we are at IA1 paths <- \"../inst/extdata\"  ### Generate event count table from ADSL and ADTTE datasets # Selection criteria for each hypothesis h_select <- tribble(   ~Hypothesis, ~Crit,   1, \"PARAMCD=='OS' & TRT01P %in% c('Xanomeline High Dose', 'Placebo')\",   2, \"PARAMCD=='OS' & TRT01P %in% c('Xanomeline Low Dose', 'Placebo')\" )  event2 <- generate_event_table(paths, h_select,   adsl_name = \"adsl\", adtte_name = \"adtte\",   key_var = \"USUBJID\", cnsr_var = \"CNSR\" )$event  event2 %>%   kbl(caption = \"Event Count - Compute from SAS Datasets Example\", align = \"l\") %>%   kable_classic_2(full_width = FALSE) ## generate correlation from events corr <- generate_corr(event)  corr %>%   kbl(caption = \"Correlation Matrix\", align = \"l\", digits = 2) %>%   kable_classic_2(full_width = FALSE) # Bonferroni bounds bound_Bonf <- generate_bounds(   type = 0, k = 2, w = w, m = m,   corr = corr, alpha = 0.025,   sf = list(sfHSD, sfHSD, sfHSD),   sfparm = list(-4, -4, -4),   t = list(c(0.5, 1), c(0.5, 1), c(0.5, 1)) )  bound_Bonf %>%   kbl(caption = \"Bonferroni bounds\", align = \"l\", digits = 4) %>%   kable_classic_2(full_width = FALSE) set.seed(1234) # WPGSD bounds, spending approach 1 bound_WPGSD <- generate_bounds(   type = 2, k = 2, w = w, m = m,   corr = corr, alpha = 0.025,   sf = sfHSD,   sfparm = -4,   t = c(min(100 / 200, 110 / 220, 225 / 450), 1) )  bound_WPGSD %>%   kbl(caption = \"WPGSD  bounds\", align = \"l\", digits = 4) %>%   kable_classic_2(full_width = FALSE) ## Observed p-values. ## The tibble must contain columns Analysis, H1, H2 etc for all hypotheses p_obs <- tribble(   ~Analysis, ~H1, ~H2, ~H3,   1, 0.01, 0.0004, 0.03,   2, 0.05, 0.002, 0.015 )  ## Closed testing ## test_result <- closed_test(bound_WPGSD, p_obs)  p_obs %>%   kbl(caption = \"Observed Nominal p-Values\", align = \"l\") %>%   kable_classic_2(full_width = FALSE) test_result %>%   kbl(caption = \"Closed Testing Results\", align = \"l\") %>%   kable_classic_2(full_width = FALSE)"},{"path":"https://merck.github.io/wpgsd/articles/wpgsd.html","id":"implementation-of-example-2-with-common-control","dir":"Articles","previous_headings":"Methods and Examples","what":"Implementation of Example 2 with Common Control","title":"Quickstart guide","text":"Similarly, codes reproduce result Example 2 Anderson et al. (2022), uses spending method 3c specified paper. Event Count Correlation Matrix Bonferroni WPGSD Bounds","code":"set.seed(1234)  # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Ex2 BH ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~# # Transition matrix in Figure A2 m <- matrix(c(   0, 0.5, 0.5,   0.5, 0, 0.5,   0.5, 0.5, 0 ), nrow = 3, byrow = TRUE) # Initial weights w <- c(1 / 3, 1 / 3, 1 / 3)  # Event count of intersection of paired hypotheses - Table 2 event <- tribble(   ~H1, ~H2, ~Analysis, ~Event,   1, 1, 1, 155,   2, 2, 1, 160,   3, 3, 1, 165,   1, 2, 1, 85,   1, 3, 1, 85,   2, 3, 1, 85,   1, 1, 2, 305,   2, 2, 2, 320,   3, 3, 2, 335,   1, 2, 2, 170,   1, 3, 2, 170,   2, 3, 2, 170 )  event %>%   kbl(caption = \"Event Count\", align = \"l\") %>%   kable_classic_2(full_width = FALSE) # Generate correlation from events corr <- generate_corr(event)  # correlation matrix in Table 4 corr %>%   kbl(caption = \"Correlation Matrix\", align = \"l\", digits = 2) %>%   kable_classic_2(full_width = FALSE) # WPGSD bounds, spending method 3c bound_WPGSD <- generate_bounds(   type = 3, k = 2, w = w, m = m, corr = corr, alpha = 0.025,   sf = list(sfLDOF, sfLDOF, sfLDOF),   sfparm = list(0, 0, 0),   t = list(c(155 / 305, 1), c(160 / 320, 1), c(165 / 335, 1)) )  # Bonferroni bounds bound_Bonf <- generate_bounds(   type = 0, k = 2, w = w, m = m, corr = corr, alpha = 0.025,   sf = list(sfLDOF, sfLDOF, sfLDOF),   sfparm = list(0, 0, 0),   t = list(c(155 / 305, 1), c(160 / 320, 1), c(165 / 335, 1)) )  bounds <- left_join(bound_Bonf, bound_WPGSD,   by = c(\"Hypotheses\", \"Analysis\"),   suffix = c(\".B\", \".W\") )  # Reorder for output bounds$order <- rep(c(5, 2, 1, 3, 6, 4, 7), 2) bounds <- bounds %>%   arrange(Analysis, order) %>%   select(-order)  # Table A6 bounds %>%   kbl(caption = \"Bonferroni and WPGSD Bounds\", align = \"l\", digits = 4) %>%   kable_classic_2(full_width = FALSE)"},{"path":"https://merck.github.io/wpgsd/articles/wpgsd.html","id":"power-considerations","dir":"Articles","previous_headings":"Methods and Examples","what":"Power Considerations","title":"Quickstart guide","text":"illustrates use WPGSD approach compute bounds analysis stage. design stage, one can take one following 2 options: 1) trial can first designed testing done weighted Bonferroni conservative sample size estimate. analysis stage, correlation can taken consideration WPGSD approach bound calculation; 2) adjust sample size downward using WPGSD approach design stage, one can power study taking minimum \\(p\\)-value bound given individual hypothesis WPGSD table (assumed correlation structure). example, \\(H_2\\) example 1, \\(\\hbox{min}(0.0011,0.0017,0.0010,0.0030)=0.0010\\) \\(k=1\\) \\(\\hbox{min}(0.0092,0.0144,0.0081,0.0238)=0.0081\\) \\(k=2\\). \\(H_2\\) bounds 0.0010 (\\(k=1\\)) 0.0081 (\\(k=2\\)) can used power \\(H_2\\). R function 2nd option development.","code":""},{"path":"https://merck.github.io/wpgsd/articles/wpgsd.html","id":"conclusions","dir":"Articles","previous_headings":"","what":"Conclusions","title":"Quickstart guide","text":"WPGSD approach provides unification previous work parametric testing group sequential design. enabled complex scenarios requires attention consonance intersection hypotheses. Although detailed closed testing required, deterrent. approach accommodates various spending approaches provides relaxed bounds improved power compared Bonferroni approach.","code":""},{"path":[]},{"path":"https://merck.github.io/wpgsd/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Keaven Anderson. Author. Zifang Guo. Author. Jing Zhao. Author. Linda Sun. Author. Yi Cui. Author. Yujie Zhao. Author, maintainer. Larry Leon. Author. Merck Sharp & Dohme Corp. Copyright holder.","code":""},{"path":"https://merck.github.io/wpgsd/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Anderson K, Guo Z, Zhao J, Sun L, Cui Y, Zhao Y, Leon L (2023). wpgsd: Weighted Parametric Group Sequential Design. https://merck.github.io/wpgsd/, https://github.com/Merck/wpgsd.","code":"@Manual{,   title = {wpgsd: Weighted Parametric Group Sequential Design},   author = {Keaven Anderson and Zifang Guo and Jing Zhao and Linda Sun and Yi Cui and Yujie Zhao and Larry Leon},   year = {2023},   note = {https://merck.github.io/wpgsd/, https://github.com/Merck/wpgsd}, }"},{"path":[]},{"path":"https://merck.github.io/wpgsd/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Weighted Parametric Group Sequential Design","text":"Install development version wpgsd GitHub:","code":"remotes::install_github(\"Merck/wpgsd\")"},{"path":"https://merck.github.io/wpgsd/index.html","id":"objective","dir":"","previous_headings":"","what":"Objective","title":"Weighted Parametric Group Sequential Design","text":"Weighted parametric group sequential design (WPGSD) allows one take advantage known correlation structure constructing efficacy bounds control family-wise error rate (FWER) group sequential design. correlation may due common observations nested populations, due common observations overlapping populations, due common observations control arm.","code":""},{"path":"https://merck.github.io/wpgsd/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Weighted Parametric Group Sequential Design","text":"Anderson, K. M., Guo, Z., Zhao, J., & Sun, L. Z. (2022). unified framework weighted parametric group sequential design. Biometrical Journal, 64(7), 1219–1239. BibTeX entry:","code":"@article{anderson2022unified,   title     = {A unified framework for weighted parametric group sequential design},   author    = {Anderson, Keaven M and Guo, Zifang and Zhao, Jing and Sun, Linda Z},   journal   = {Biometrical Journal},   volume    = {64},   number    = {7},   pages     = {1219--1239},   year      = {2022},   publisher = {Wiley Online Library} }"},{"path":"https://merck.github.io/wpgsd/reference/closed_test.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform closed testing procedure — closed_test","title":"Perform closed testing procedure — closed_test","text":"Perform closed testing procedure","code":""},{"path":"https://merck.github.io/wpgsd/reference/closed_test.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform closed testing procedure — closed_test","text":"","code":"closed_test(bounds, p_obs)"},{"path":"https://merck.github.io/wpgsd/reference/closed_test.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform closed testing procedure — closed_test","text":"bounds tibble nominal p-value boundaries generate_bounds() containing columns Analysis, Hypotheses, H1, H2, etc. p_obs tibble observed p-values containing columns Analysis, H1, H2, etc.","code":""},{"path":"https://merck.github.io/wpgsd/reference/closed_test.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform closed testing procedure — closed_test","text":"outcome matrix summarizing testing results.","code":""},{"path":"https://merck.github.io/wpgsd/reference/closed_test.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform closed testing procedure — closed_test","text":"","code":"p_obs <- dplyr::bind_rows(   tibble::tibble(Analysis = 1, H1 = 0.001, H2 = 0.001),   tibble::tibble(Analysis = 2, H1 = 0.001, H2 = 0.001) ) bound <- tibble::tribble(   ~Analysis, ~Hypotheses, ~H1, ~H2,   1, \"H1\", 0.02, NA,   1, \"H1, H2\", 0.0001, 0.00001,   1, \"H2\", NA, 0.003,   2, \"H1\", 0.02, NA,   2, \"H1, H2\", 0.02, 0.00001,   2, \"H2\", NA, 0.003 )  closed_test <- closed_test(bound, p_obs)"},{"path":"https://merck.github.io/wpgsd/reference/find_astar.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility function for root-finding to compute crossing probabilities\nwith the overall alpha spending approach — find_astar","title":"Utility function for root-finding to compute crossing probabilities\nwith the overall alpha spending approach — find_astar","text":"Utility function root-finding compute crossing probabilities overall alpha spending approach","code":""},{"path":"https://merck.github.io/wpgsd/reference/find_astar.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility function for root-finding to compute crossing probabilities\nwith the overall alpha spending approach — find_astar","text":"","code":"find_astar(   a,   alpha_prev = NULL,   astar,   w,   sig,   maxpts = 50000,   abseps = 1e-05,   ... )"},{"path":"https://merck.github.io/wpgsd/reference/find_astar.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility function for root-finding to compute crossing probabilities\nwith the overall alpha spending approach — find_astar","text":"Cumulative overall alpha spending current analysis. alpha_prev alpha boundary previous interim analyses using WPGSD approach. astar Total nominal alpha level current analysis WPGSD approach. w Vector alpha weights current analysis. sig Correlation matrix previous current analyses test statistics. maxpts GenzBretz function maximum number function values integer. abseps GenzBretz function absolute error tolerance. ... Additional arguments.","code":""},{"path":"https://merck.github.io/wpgsd/reference/find_astar.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utility function for root-finding to compute crossing probabilities\nwith the overall alpha spending approach — find_astar","text":"Difference. 0 astar identified.","code":""},{"path":"https://merck.github.io/wpgsd/reference/find_astar.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Utility function for root-finding to compute crossing probabilities\nwith the overall alpha spending approach — find_astar","text":"","code":"library(tibble) library(mvtnorm)  # Input event count of intersection of paired hypotheses - Table 2 my_event <- tribble(   ~H1, ~H2, ~Analysis, ~Event,   1, 1, 1, 155,   2, 2, 1, 160,   3, 3, 1, 165,   1, 2, 1, 85,   1, 3, 1, 85,   2, 3, 1, 85,   1, 1, 2, 305,   2, 2, 2, 320,   3, 3, 2, 335,   1, 2, 2, 170,   1, 3, 2, 170,   2, 3, 2, 170 )  # Generate correlation from events my_corr <- generate_corr(my_event)  # Find the inflation factor for H1, H2 at analysis 1 find_astar(   a = 0.0008708433,   alpha_prev = NULL,   aprime = c(0.0004588644, 0.0004119789),   astar = 1,   w = c(0.5, 0.5),   sig = my_corr[     colnames(my_corr) %in% c(\"H1_A1\", \"H2_A1\"),     colnames(my_corr) %in% c(\"H1_A1\", \"H2_A1\")   ] ) #> [1] 0.6583884 #> attr(,\"error\") #> [1] 1e-15 #> attr(,\"msg\") #> [1] \"Normal Completion\""},{"path":"https://merck.github.io/wpgsd/reference/find_xi.html","id":null,"dir":"Reference","previous_headings":"","what":"Utility function for root-finding to compute inflation factor xi\nwith the separate alpha spending approach — find_xi","title":"Utility function for root-finding to compute inflation factor xi\nwith the separate alpha spending approach — find_xi","text":"Utility function root-finding compute inflation factor xi separate alpha spending approach","code":""},{"path":"https://merck.github.io/wpgsd/reference/find_xi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Utility function for root-finding to compute inflation factor xi\nwith the separate alpha spending approach — find_xi","text":"","code":"find_xi(   a,   alpha_prev = NULL,   aprime,   xi,   sig,   maxpts = 50000,   abseps = 1e-05,   ... )"},{"path":"https://merck.github.io/wpgsd/reference/find_xi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Utility function for root-finding to compute inflation factor xi\nwith the separate alpha spending approach — find_xi","text":"Sum cumulative alpha spending Bonferroni approach. alpha_prev alpha boundary previous interim analyses using MTP approach. aprime Nominal alpha boundary Bonferroni approach. xi Inflation factor. sig Correlation matrix previous current analyses test statistics. maxpts GenzBretz function maximum number function values integer. abseps GenzBretz function absolute error tolerance. ... Additional arguments.","code":""},{"path":"https://merck.github.io/wpgsd/reference/find_xi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Utility function for root-finding to compute inflation factor xi\nwith the separate alpha spending approach — find_xi","text":"Difference. 0 xi identified.","code":""},{"path":"https://merck.github.io/wpgsd/reference/find_xi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Utility function for root-finding to compute inflation factor xi\nwith the separate alpha spending approach — find_xi","text":"","code":"library(tibble)  # Input event count of intersection of paired hypotheses - Table 2 my_event <- tribble(   ~H1, ~H2, ~Analysis, ~Event,   1, 1, 1, 155,   2, 2, 1, 160,   3, 3, 1, 165,   1, 2, 1, 85,   1, 3, 1, 85,   2, 3, 1, 85,   1, 1, 2, 305,   2, 2, 2, 320,   3, 3, 2, 335,   1, 2, 2, 170,   1, 3, 2, 170,   2, 3, 2, 170 )  # Generate correlation from events my_corr <- generate_corr(my_event)  # Find the inflation factor for H1, H2 at analysis 1 find_xi(   a = 0.0008708433,   alpha_prev = NULL,   aprime = c(0.0004588644, 0.0004119789),   xi = 1,   sig = my_corr[     colnames(my_corr) %in% c(\"H1_A1\", \"H2_A1\"),     colnames(my_corr) %in% c(\"H1_A1\", \"H2_A1\")   ] ) #> [1] -2.237679e-05 #> attr(,\"error\") #> [1] 1e-15 #> attr(,\"msg\") #> [1] \"Normal Completion\""},{"path":"https://merck.github.io/wpgsd/reference/generate_bounds.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute p-value boundaries of the parametric MTP method with overall\nalpha spending for all hypotheses — generate_bounds","title":"Compute p-value boundaries of the parametric MTP method with overall\nalpha spending for all hypotheses — generate_bounds","text":"Compute p-value boundaries parametric MTP method overall alpha spending hypotheses","code":""},{"path":"https://merck.github.io/wpgsd/reference/generate_bounds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute p-value boundaries of the parametric MTP method with overall\nalpha spending for all hypotheses — generate_bounds","text":"","code":"generate_bounds(   type = 1,   k = 2,   w = w,   m = m,   corr = corr,   alpha = 0.025,   cum_alpha = NULL,   maxpts = 50000,   abseps = 1e-05,   tol = 1e-10,   sf = gsDesign::sfHSD,   sfparm = -4,   t = c(0.5, 1),   ... )"},{"path":"https://merck.github.io/wpgsd/reference/generate_bounds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute p-value boundaries of the parametric MTP method with overall\nalpha spending for all hypotheses — generate_bounds","text":"type Boundary type. 0 = Bonferroni. Separate alpha spending hypotheses. 1 = Fixed alpha spending hypotheses. Method 3a manuscript. 2 = Overall alpha spending hypotheses. Method 3b manuscript. 3 = Separate alpha spending hypotheses. Method 3c manuscript. k Number analyses current analysis. w Initial weights. m Transition matrix. corr Correlation matrix test statistics current analysis. dim = k * length(w). alpha Overall alpha. cum_alpha Cumulative alpha spent analysis. required type = 1. maxpts GenzBretz function maximum number function values integer. abseps GenzBretz function absolute error tolerance. tol Find root tolerance. sf list alpha spending functions spend alpha hypotheses. type = 0 3 length equals number hypotheses. type = 1 sf needed. type = 2 first component used. sfparm list parameters supplied sfs. type = 0 3 length equals number hypotheses. type = 1 sfparm needed. type = 2 first component used. t list information fraction used alpha spending, may different actual information fraction. component corresponds hypothesis. type = 0 3 length equals number hypotheses. type = 1 t needed. type = 2 first component used. ... Additional arguments.","code":""},{"path":"https://merck.github.io/wpgsd/reference/generate_bounds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute p-value boundaries of the parametric MTP method with overall\nalpha spending for all hypotheses — generate_bounds","text":"tibble k * (2^(n_hypotheses - 1)) rows p-value boundaries. Inflation factor also provided type = 3.","code":""},{"path":"https://merck.github.io/wpgsd/reference/generate_bounds.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute p-value boundaries of the parametric MTP method with overall\nalpha spending for all hypotheses — generate_bounds","text":"","code":"library(tibble)  # Build the transition matrix m <- matrix(c(   0, 0.5, 0.5,   0.5, 0, 0.5,   0.5, 0.5, 0 ), nrow = 3, byrow = TRUE)  # Initialize weights w <- c(1 / 3, 1 / 3, 1 / 3)  # Input information fraction IF_IA <- c(155 / 305, 160 / 320, 165 / 335)  # Input event count of intersection of paired hypotheses - Table 2 event <- tribble(   ~H1, ~H2, ~Analysis, ~Event,   1, 1, 1, 155,   2, 2, 1, 160,   3, 3, 1, 165,   1, 2, 1, 85,   1, 3, 1, 85,   2, 3, 1, 85,   1, 1, 2, 305,   2, 2, 2, 320,   3, 3, 2, 335,   1, 2, 2, 170,   1, 3, 2, 170,   2, 3, 2, 170 )  # Generate correlation from events gs_corr <- generate_corr(event)  # Generate bounds generate_bounds(   type = 3,   k = 2,   w = w,   m = m,   corr = gs_corr,   alpha = 0.025,   sf = list(gsDesign::sfLDOF, gsDesign::sfLDOF, gsDesign::sfLDOF),   sfparm = list(0, 0, 0),   t = list(c(IF_IA[1], 1), c(IF_IA[2], 1), c(IF_IA[3], 1)) ) #> # A tibble: 14 × 6 #>    Analysis Hypotheses        H1        H2        H3    xi #>       <int> <chr>          <dbl>     <dbl>     <dbl> <dbl> #>  1        1 H1          0.00167  NA        NA         1    #>  2        1 H1, H2      0.000471  0.000423 NA         1.03 #>  3        1 H1, H2, H3  0.000223  0.000197  0.000177  1.04 #>  4        1 H1, H3      0.000470 NA         0.000382  1.02 #>  5        1 H2         NA         0.00153  NA         1    #>  6        1 H2, H3     NA         0.000421  0.000381  1.02 #>  7        1 H3         NA        NA         0.00140   1    #>  8        2 H1          0.0245   NA        NA         1    #>  9        2 H1, H2      0.0135    0.0135   NA         1.09 #> 10        2 H1, H2, H3  0.00949   0.00950   0.00951   1.15 #> 11        2 H1, H3      0.0135   NA         0.0135    1.09 #> 12        2 H2         NA         0.0245   NA         1    #> 13        2 H2, H3     NA         0.0134    0.0134    1.09 #> 14        2 H3         NA        NA         0.0245    1"},{"path":"https://merck.github.io/wpgsd/reference/generate_corr.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate correlation matrix based on event counts — generate_corr","title":"Generate correlation matrix based on event counts — generate_corr","text":"Generate correlation matrix based event counts","code":""},{"path":"https://merck.github.io/wpgsd/reference/generate_corr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate correlation matrix based on event counts — generate_corr","text":"","code":"generate_corr(event)"},{"path":"https://merck.github.io/wpgsd/reference/generate_corr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate correlation matrix based on event counts — generate_corr","text":"event Event count hypothesis analysis, including event count intersection hypotheses. contains 4 columns: H1, H2, Analysis, Event. H1 needs listed 1, 2, 3, etc. numbers.","code":""},{"path":"https://merck.github.io/wpgsd/reference/generate_corr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate correlation matrix based on event counts — generate_corr","text":"correlation matrix.","code":""},{"path":"https://merck.github.io/wpgsd/reference/generate_corr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate correlation matrix based on event counts — generate_corr","text":"","code":"library(tibble)  # build the transition matrix m <- matrix(c(   0, 0.5, 0.5,   0.5, 0, 0.5,   0.5, 0.5, 0 ), nrow = 3, byrow = TRUE) # initialize weights w <- c(1 / 3, 1 / 3, 1 / 3)  # input event count of intersection of paired hypotheses - Table 2 event <- tribble(   ~H1, ~H2, ~Analysis, ~Event,   1, 1, 1, 155,   2, 2, 1, 160,   3, 3, 1, 165,   1, 2, 1, 85,   1, 3, 1, 85,   2, 3, 1, 85,   1, 1, 2, 305,   2, 2, 2, 320,   3, 3, 2, 335,   1, 2, 2, 170,   1, 3, 2, 170,   2, 3, 2, 170 )  # generate correlation from events gs_corr <- generate_corr(event)"},{"path":"https://merck.github.io/wpgsd/reference/generate_event_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate table of event counts from ADSL and ADTTE SAS datasets — generate_event_table","title":"Generate table of event counts from ADSL and ADTTE SAS datasets — generate_event_table","text":"Generate table event counts ADSL ADTTE SAS datasets","code":""},{"path":"https://merck.github.io/wpgsd/reference/generate_event_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate table of event counts from ADSL and ADTTE SAS datasets — generate_event_table","text":"","code":"generate_event_table(paths, h_select, adsl_name, adtte_name, key_var, cnsr_var)"},{"path":"https://merck.github.io/wpgsd/reference/generate_event_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate table of event counts from ADSL and ADTTE SAS datasets — generate_event_table","text":"paths vector paths analysis datasets. Length equal number analyses completed h_select Selection criterion hypothesis. tibble containing 2 columns Hypothesis Crit adsl_name SAS dataset name subject-level analysis data. Usually \"adsl\". adtte_name SAS dataset name time--event analysis data. Usually \"adtte\". key_var Key variable join adsl adtte datasets. e.g. \"USUBJID\" \"SUBJID\" cnsr_var Variable indicate censoring (1 = censor; 0 = event). e.g. \"CNSR\".","code":""},{"path":"https://merck.github.io/wpgsd/reference/generate_event_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate table of event counts from ADSL and ADTTE SAS datasets — generate_event_table","text":"list two components: event: event count table input generate_bounds(). dsets: analysis datasets hypothesis.","code":""},{"path":"https://merck.github.io/wpgsd/reference/generate_event_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate table of event counts from ADSL and ADTTE SAS datasets — generate_event_table","text":"","code":"library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union  paths <- system.file(\"extdata/\", package = \"wpgsd\")  # Selection criteria for each hypothesis h_select <- tibble::tribble(   ~Hypothesis, ~Crit,   1, \"PARAMCD == 'OS' & TRT01P %in% c('Xanomeline High Dose', 'Placebo')\",   2, \"PARAMCD == 'OS' & TRT01P %in% c('Xanomeline Low Dose', 'Placebo')\" )  event <- generate_event_table(paths, h_select,   adsl_name = \"adsl\", adtte_name = \"adtte\",   key_var = \"USUBJID\", cnsr_var = \"CNSR\" )$event  event %>%   kableExtra::kbl(caption = \"Event Count - Compute from SAS Datasets Example\", align = \"l\") %>%   kableExtra::kable_classic_2(full_width = FALSE) #> <table class=\" lightable-classic-2\" style='font-family: \"Arial Narrow\", \"Source Sans Pro\", sans-serif; width: auto !important; margin-left: auto; margin-right: auto;'> #> <caption>Event Count - Compute from SAS Datasets Example<\/caption> #>  <thead> #>   <tr> #>    <th style=\"text-align:left;\"> H1 <\/th> #>    <th style=\"text-align:left;\"> H2 <\/th> #>    <th style=\"text-align:left;\"> Analysis <\/th> #>    <th style=\"text-align:left;\"> Event <\/th> #>   <\/tr> #>  <\/thead> #> <tbody> #>   <tr> #>    <td style=\"text-align:left;\"> 1 <\/td> #>    <td style=\"text-align:left;\"> 1 <\/td> #>    <td style=\"text-align:left;\"> 1 <\/td> #>    <td style=\"text-align:left;\"> 66 <\/td> #>   <\/tr> #>   <tr> #>    <td style=\"text-align:left;\"> 2 <\/td> #>    <td style=\"text-align:left;\"> 2 <\/td> #>    <td style=\"text-align:left;\"> 1 <\/td> #>    <td style=\"text-align:left;\"> 59 <\/td> #>   <\/tr> #>   <tr> #>    <td style=\"text-align:left;\"> 1 <\/td> #>    <td style=\"text-align:left;\"> 2 <\/td> #>    <td style=\"text-align:left;\"> 1 <\/td> #>    <td style=\"text-align:left;\"> 45 <\/td> #>   <\/tr> #> <\/tbody> #> <\/table>"},{"path":"https://merck.github.io/wpgsd/reference/tidyeval.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy eval helpers — tidyeval","title":"Tidy eval helpers — tidyeval","text":"page lists tidy eval tools reexported package rlang. learn using tidy eval scripts packages high level, see dplyr programming vignette ggplot2 packages vignette. Metaprogramming section Advanced R may also useful deeper dive. tidy eval operators {{, !!, !!! syntactic constructs specially interpreted tidy eval functions. mostly need {{, !! !!! advanced operators use simple cases. curly-curly operator {{ allows tunnel data-variables passed function arguments inside tidy eval functions. {{ designed individual arguments. pass multiple arguments contained dots, use ... normal way.   enquo() enquos() delay execution one several function arguments. former returns single expression, latter returns list expressions. defused, expressions longer evaluate . must injected back evaluation context !! (single expression) !!! (list expressions).   simple case, code equivalent usage {{ ... . Defusing enquo() enquos() needed complex cases, instance need inspect modify expressions way. .data pronoun object represents current slice data. variable name string, use .data pronoun subset variable [[.   Another tidy eval operator :=. makes possible use glue curly-curly syntax LHS =. technical reasons, R language support complex expressions left =, use := workaround.   Many tidy eval functions like dplyr::mutate() dplyr::summarise() give automatic name unnamed inputs. need create sort automatic names , use as_label(). instance, glue-tunnelling syntax can reproduced manually :   Expressions defused enquo() (tunnelled {{) need simple column names, can arbitrarily complex. as_label() handles cases gracefully. code assumes simple column name, use as_name() instead. safer throws error input name expected.","code":"my_function <- function(data, var, ...) {   data %>%     group_by(...) %>%     summarise(mean = mean({{ var }})) } my_function <- function(data, var, ...) {   # Defuse   var <- enquo(var)   dots <- enquos(...)    # Inject   data %>%     group_by(!!!dots) %>%     summarise(mean = mean(!!var)) } my_var <- \"disp\" mtcars %>% summarise(mean = mean(.data[[my_var]])) my_function <- function(data, var, suffix = \"foo\") {   # Use `{{` to tunnel function arguments and the usual glue   # operator `{` to interpolate plain strings.   data %>%     summarise(\"{{ var }}_mean_{suffix}\" := mean({{ var }})) } my_function <- function(data, var, suffix = \"foo\") {   var <- enquo(var)   prefix <- as_label(var)   data %>%     summarise(\"{prefix}_mean_{suffix}\" := mean(!!var)) }"},{"path":"https://merck.github.io/wpgsd/news/index.html","id":"wpgsd-development-version","dir":"Changelog","previous_headings":"","what":"wpgsd (development version)","title":"wpgsd (development version)","text":"wpgsd R package now available GitHub, can easily installed prefer use specific version, please install v0.1.0 specifies version number can custom .","code":"devtools::install_github(\"Merck/wpgsd\") devtools::install_github(\"Merck/wpgsd@v0.1.0\")"},{"path":"https://merck.github.io/wpgsd/news/index.html","id":"wpgsd-development-version-1","dir":"Changelog","previous_headings":"","what":"wpgsd 0.1.0","title":"wpgsd (development version)","text":"Initial release GitHub","code":""}]
